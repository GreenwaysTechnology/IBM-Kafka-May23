				Kafka fundamentals
.....................................................................................
What is kafka ? Apache Kafka

Kafka is a java program, written in java.

Kafka was originally developed at Linkedin, and later it was open sourced, 
Jay Kreps, Neha ,and juno Rao who created kafka.

If you want to understand kafka , just think about , How logs are working.

Log is just information about what happend in your system.
for instance, some warnings, some errors, some info,tracing.

Log information is recored in a file which is called log file.

How log works?
 log works based on the concept called append only, which is mere file io.
file io involves read and write something(data).

Writing data into file in two mode.

=>replace mode  
   data is written into file which will be replaced or edited later.
=>Append only mode
   data is written into file at end of every line just add entry at last line of file, which is called append only


Kafka is based on log, Kafka is just logger system.

Kafak is based on commit log.

What is commit log?
    In data management platforms, a commit is making of set of tenative changes permanent.
 making the end of a transaction and providing Durablity to ACID transactions.
The record of commits is called "commit log".

What Kafka is going to record into commit log?
   Kafka was desigend to capture informations(data) or events about system.
 What is happening in the software system, i want to record every thing.


What is event?
  something that happens, or happened.
An event records the fact that "something happened" in the world or in your biz, or in your life, around you.

eg:
  today stock avg price is 100$
  i met my friend yesterday at east coast road
  Made a payment of $500 to Ramesh

Imagine i need some body/something should record every activity of my life from early moring when i get up and till sleep.

 There is a system to record every events of your life that is called kafka.

Kafka is event recorder, Kafaka records events happened in the system.

Kafak is event processing software, which process events.

Events Types:
............
1.Past events - Happened
      Made a payment of $500 to Ramesh
2.present events - on going / on progress  events

Event Streams:
.............
Stream is nothing but  on going or on progress over period of time.
We can record on going events /on progress events into system


"An Event is any type of action or incident or chage that's idenfified or recorded by software or applications eg a payment, a website click or temperature reading, along with with a description of what happended"

"A event is a coimbination of notification", the element of when-ness that can be used to trigger some other activity and state.

"event contains two things"
 =>What happened - name of the event
 =>State - data


state:
.......
 The state is nothing data 

How generally data/state is stored?
   information is stored in database as table which represents the state of something
eg user- id,name,city

can we store events in databases?
 We cant  store all events in the database

Modern data modeling:
 Now a days instead of thingking "things(Customer,Order,Payment)" first, people starts thinking events first
 instead of stroing things into db, we store events.

events also has some state like "things"

"events has some description of what happened with it, but primary idea is that event is an indication in time that thing took place"
    
      "You cant store every events happened or happing in the system into db"

How do you store events?
  Logs - Log is structured and the sequence of the events occured in the method calls.
.....................................................................................
			  What is apache kafka?

Kafka is a software system for managining these logs using a fairly standard,the same historical term called "topics".

What is topic?
 Topic is logical structure to store events which is similar to database schema and database table

What is event according to kafka?

  Event is like key-value pair structure just like table row of data

Topic is logical structure which stores sequence of information
Topic is log of events.

Features of logcs:
=>logs are easy to understand
=>logs are append only
=>logs are immutable
=>logs are highly durable=>By default all events are recorded into file system, there is no concept like non durable that is we never store data in memory.
=>Can only seek by offset, not indexed
.....................................................................................
			Kafka is highly Distributed
.....................................................................................
Traditionally, log processors are not scalable or highly available.
Kafka is distributed log processing system, which  scals log data into multiple system.
...................................................................................
			Kafak Distribution - Kafka setup
..................................................................................

Kafka distribution:
 Kafka is availble in two distribution

1.Apache Kafka
  It is opensource version of kafka
2.Confulent kafka
  It is abstraction of apache kafka , commerical version of Apache kafka

Apache Kafka vs Confulent kafka:
https://www.confluent.io/apache-kafka-vs-confluent/


Platforms:
1.bare metal 
 kafka is distributed for all os

1.windows : may be good for basic use cases
2.linux  : recommended for advanced use cases
3.mac : recommended for advanced use cases.

2.VM env
  you can setup kafka on any industry standard vms -  oracle virtual box

3.Container based distributed - docker and kubernets
    it is highly recommend for dev and also even in productions.
....................................................................................
			Linux Setup
................................................................................
windows Sub System - Linux -  wsl
https://www.confluent.io/blog/set-up-and-run-kafka-on-windows-linux-wsl-2/?utm_medium=sem&utm_source=google&utm_campaign=ch.sem_br.nonbrand_tp.prs_tgt.dsa_mt.dsa_rgn.india_lng.eng_dv.all_con.blog&utm_term=&creative=&device=c&placement=&gclid=CjwKCAiAioifBhAXEiwApzCztroeBf99rY2AQ8kqOxzpA4vWwv_pe4qIQ682fYDA6hF9JJSJ6gN61hoCJQwQAvD_BwE.

After installing :


sudo apt install openjdk-11-jdk -y


https://archive.apache.org/dist/kafka/3.4.0/kafka-3.4.0-src.tgz  

tar -xzf kafka-3.4.0-src.tgz 
cd kafka_2.13-2.6.0


we need to look at folder structure

subugee@LAPTOP-R2TGGFDL:~/session/kafka-3-4-0$ ls -al
total 60
drwxr-xr-x 6 subugee subugee  4096 Jul 28  2020 .
drwxr-xr-x 3 subugee subugee  4096 Feb  7 16:37 ..
drwxr-xr-x 3 subugee subugee  4096 Jul 28  2020 bin
drwxr-xr-x 2 subugee subugee  4096 Jul 28  2020 config
drwxr-xr-x 2 subugee subugee  4096 Feb  7 16:37 libs
-rw-r--r-- 1 subugee subugee 29975 Jul 28  2020 LICENSE
-rw-r--r-- 1 subugee subugee   337 Jul 28  2020 NOTICE
drwxr-xr-x 2 subugee subugee  4096 Jul 28  2020 site-docs
.....................................................................................

Bin folder contains kafka distribution for linux

subugee@LAPTOP-R2TGGFDL:~/ibmkafkamay23/kafka-3.4.0-src/bin$ ls
connect-distributed.sh        kafka-dump-log.sh              kafka-server-stop.sh
connect-mirror-maker.sh       kafka-features.sh              kafka-storage.sh
connect-standalone.sh         kafka-get-offsets.sh           kafka-streams-application-reset.sh
kafka-acls.sh                 kafka-leader-election.sh       kafka-topics.sh
kafka-broker-api-versions.sh  kafka-log-dirs.sh              kafka-transactions.sh
kafka-cluster.sh              kafka-metadata-quorum.sh       kafka-verifiable-consumer.sh
kafka-configs.sh              kafka-metadata-shell.sh        kafka-verifiable-producer.sh
kafka-console-consumer.sh     kafka-mirror-maker.sh          trogdor.sh
kafka-console-producer.sh     kafka-producer-perf-test.sh    windows
kafka-consumer-groups.sh      kafka-reassign-partitions.sh   zookeeper-security-migration.sh
kafka-consumer-perf-test.sh   kafka-replica-verification.sh  zookeeper-server-start.sh
kafka-delegation-tokens.sh    kafka-run-class.sh             zookeeper-server-stop.sh
kafka-delete-records.sh       kafka-server-start.sh          zookeeper-shell.sh


windows folder contains kafka windows distribution

subugee@LAPTOP-R2TGGFDL:~/ibmkafkamay23/kafka-3.4.0-src/bin$ cd windows
subugee@LAPTOP-R2TGGFDL:~/ibmkafkamay23/kafka-3.4.0-src/bin/windows$ ls
connect-distributed.bat        kafka-delete-records.bat        kafka-run-class.bat
connect-standalone.bat         kafka-dump-log.bat              kafka-server-start.bat
kafka-acls.bat                 kafka-get-offsets.bat           kafka-server-stop.bat
kafka-broker-api-versions.bat  kafka-leader-election.bat       kafka-storage.bat
kafka-configs.bat              kafka-log-dirs.bat              kafka-streams-application-reset.bat
kafka-console-consumer.bat     kafka-metatada-quorum.bat       kafka-topics.bat
kafka-console-producer.bat     kafka-mirror-maker.bat          kafka-transactions.bat
kafka-consumer-groups.bat      kafka-producer-perf-test.bat    zookeeper-server-start.bat
kafka-consumer-perf-test.bat   kafka-reassign-partitions.bat   zookeeper-server-stop.bat
kafka-delegation-tokens.bat    kafka-replica-verification.bat  zookeeper-shell.bat
...................................................................................
			Core concepts of Kafka
...................................................................................

Broker:
  Since Kafka is java program which is deployed on jvm,kafka runs on the jvm process
Which is called kafka server or kafka broker

By default kafka broker is distributed(Scalable-running mulitiple instance of the same broker) across multiple machines or same machine


Cluster:
  A kafak cluster is  a system that consits of serveral brokers
 The cluster helps to distribute work loads equally among replicas

By default kafka is clustered commit log system.

In order to manage cluster we have cluster management software.

There are two cluster manager supported by kafka

1.Apache ZooKeeper:
  Zookeeper is a centeralized service for maintaining configuration information, naming,providing distributed synchronization and providing group services

2.KRaft:
  Apache Kafka Raft , KRaft is conensus protocal that was introduced to replace Apach Zookeeper for meta data management.

Zookeeper role:
=>Cluster Management
=>Failure detection and recovery
=>Store ACL and secrets

Lab 1: Kafka cluster setup
..........................
Single broker , single zookeeper

Broker and zookeeper requires configuration files  in order to start kafka broker and zookeeper

Zooker config file:
config/zookeeper.properties

dataDir=/tmp/zookeeper
the directory where the snapshot is stored, information about the cluster

clientPort=2181
  The port at which clients connect.
  Who is client ? Kafak Broker is client

Server/Broker config folder:

config/server.properties
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

Steps:

1.Start Zookeeper

./bin/zookeeper-server-start.sh  config/zookeeper.properties
Classpath is empty. Please build the project first e.g. by running './gradlew jar -PscalaVersion=2.13.10'


if you see the above error that means your distribution is source code distribution
so you have to build it.

How to build?
./gradlew jar -PscalaVersion=2.13.10

after building again start the server

 ./bin/zookeeper-server-start.sh  config/zookeeper.properties

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/subugee/ibmkafkamay23/kafka-3.4.0-src/tools/build/dependant-libs-2.13.10/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/subugee/ibmkafkamay23/kafka-3.4.0-src/trogdor/build/dependant-libs-2.13.10/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/subugee/ibmkafkamay23/kafka-3.4.0-src/connect/runtime/build/dependant-libs/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/subugee/ibmkafkamay23/kafka-3.4.0-src/connect/mirror/build/dependant-libs/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]

How to start kafka broker?
kafka-3.4.0-src$ ./bin/kafka-server-start.sh config/server.properties
...................................................................................
			 Exploring kafka logs
....................................................................................

Cluster logs - Zookeeper or KRaft:
..................................
tmp/zookeeper

Kafak Logs:
/tmp/kafka-logs
.......................................XXX...........................................
				Topic
..................................................................................

What is topic?
There are lot of events in the world.
We need to organize them in the system , Now Kafka fundamental unit  of event  organization is called “Topic”

Topic is just like table in relational database.

As a developer using kafka, the topic is the abstraction for logs

You can create different types of topics to hold different types of events

You can filter and transform the different topics,coimbine them into one topic

A topic is log of events,logs are easy to understand

Topics are simple data structures with well known semantics, They are append only

When you write message(event),it always goes on the end.

When you read message from the logs by seeking offset in the log.

Logs are fundamental durable things, Traditional messaging  systems have topics and queues, which store messages temporarily to buffer them between source and designation

Since topics are logs, which is always permenant.

You can store logs(events) as short to as long as years or even to retain messages indefinitely.

Steps :

How to create topic?

in order to create topic , you need somebody to create topic.

Producer:
 A producer just a program written in any language, or even producer cli, responsible to send/publish events to the broker.
 A Producer publish events to broker's topic

Lab: how to create topic using "kafka-topics"

This tool helps to create, delete, describe, or change a topic


./bin/kafka-topics.sh --help

Option                                   Description
------                                   -----------
--alter                                  Alter the number of partitions,
                                           replica assignment, and/or
                                           configuration for the topic.
--at-min-isr-partitions                  if set when describing topics, only
                                           show partitions whose isr count is
                                           equal to the configured minimum.
--bootstrap-server <String: server to    REQUIRED: The Kafka server to connect
  connect to>                              to.
--command-config <String: command        Property file containing configs to be
  config property file>                    passed to Admin Client. This is used
                                           only with --bootstrap-server option
                                           for describing and altering broker
                                           configs.
--config <String: name=value>            A topic configuration override for the
                                           topic being created or altered. The
                                           following is a list of valid
                                           configurations:
                                                cleanup.policy
                                                compression.type
                                                delete.retention.ms
                                                file.delete.delay.ms
                                                flush.messages
                                                flush.ms
                                                follower.replication.throttled.
                                           replicas
                                                index.interval.bytes
                                                leader.replication.throttled.replicas
                                                local.retention.bytes
                                                local.retention.ms
                                                max.compaction.lag.ms
                                                max.message.bytes
                                                message.downconversion.enable
                                                message.format.version
                                                message.timestamp.difference.max.ms
                                                message.timestamp.type
                                                min.cleanable.dirty.ratio
                                                min.compaction.lag.ms
                                                min.insync.replicas
                                                preallocate
                                                remote.storage.enable
                                                retention.bytes
                                                retention.ms
                                                segment.bytes
                                                segment.index.bytes
                                                segment.jitter.ms
                                                segment.ms
                                                unclean.leader.election.enable
                                         See the Kafka documentation for full
                                           details on the topic configs. It is
                                           supported only in combination with --
                                           create if --bootstrap-server option
                                           is used (the kafka-configs CLI
                                           supports altering topic configs with
                                           a --bootstrap-server option).
--create                                 Create a new topic.
--delete                                 Delete a topic
--delete-config <String: name>           A topic configuration override to be
                                           removed for an existing topic (see
                                           the list of configurations under the
                                           --config option). Not supported with
                                           the --bootstrap-server option.
--describe                               List details for the given topics.
--disable-rack-aware                     Disable rack aware replica assignment
--exclude-internal                       exclude internal topics when running
                                           list or describe command. The
                                           internal topics will be listed by
                                           default
--help                                   Print usage information.
--if-exists                              if set when altering or deleting or
                                           describing topics, the action will
                                           only execute if the topic exists.
--if-not-exists                          if set when creating topics, the
                                           action will only execute if the
                                           topic does not already exist.
--list                                   List all available topics.
--partitions <Integer: # of partitions>  The number of partitions for the topic
                                           being created or altered (WARNING:
                                           If partitions are increased for a
                                           topic that has a key, the partition
                                           logic or ordering of the messages
                                           will be affected). If not supplied
                                           for create, defaults to the cluster
                                           default.
--replica-assignment <String:            A list of manual partition-to-broker
  broker_id_for_part1_replica1 :           assignments for the topic being
  broker_id_for_part1_replica2 ,           created or altered.
  broker_id_for_part2_replica1 :
  broker_id_for_part2_replica2 , ...>
--replication-factor <Integer:           The replication factor for each
  replication factor>                      partition in the topic being
                                           created. If not supplied, defaults
                                           to the cluster default.
--topic <String: topic>                  The topic to create, alter, describe
                                           or delete. It also accepts a regular
                                           expression, except for --create
                                           option. Put topic name in double
                                           quotes and use the '\' prefix to
                                           escape regular expression symbols; e.
                                           g. "test\.topic".
--topic-id <String: topic-id>            The topic-id to describe.This is used
                                           only with --bootstrap-server option
                                           for describing topics.
--topics-with-overrides                  if set when describing topics, only
                                           show topics that have overridden
                                           configs
--unavailable-partitions                 if set when describing topics, only
                                           show partitions whose leader is not
                                           available
--under-min-isr-partitions               if set when describing topics, only
                                           show partitions whose isr count is
                                           less than the configured minimum.
--under-replicated-partitions            if set when describing topics, only
                                           show under replicated partitions
--version                                Display Kafka version.

...................................................................................

--create                                 Create a new topic.

./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic todo-topic

Created topic todo-topic.

After creating topic, you can explore log file location

/tmp/kafka-logs
       |
     todo-topic-0

Inside folder kafka-logs, todo-topic-0  is going to encapsulate topics as folders.

if you create more topics, each topic is represented as folder.

/tmp/kafka-logs
       |
     todo-topic-0
     message-topic-0

here what is zero ?
  zero represents broker id by default
.....................................................................................
			How to look at the topic structure/topic
.....................................................................................

--describe --topic todo-topic

 ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic todo-topic

Topic: todo-topic 
TopicId: Hz9XqoH4SYWpottd-uqakA
PartitionCount: 1
ReplicationFactor: 1
Configs:
 Topic: todo-topic       Partition: 0    Leader: 0       Replicas: 0     Isr: 0
....................................................................................
		       How to delete the topic
.....................................................................................
./bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic todo-topic

once the delete command is executed, the topic name is renamed rather it wont delete from the Permantently.

It simply rename the folder name 
todo-topic-0.3c849068285f41bd986eeb4b7f79c35f-delete
.....................................................................................
			How to restore deleted topics
......................................................................................
./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic todo-topic

You will able to get deleted topics again.
.....................................................................................
		How to publish messages into Kafka
....................................................................................

./bin/kafka-console-producer.sh --help

Option                                   Description
------                                   -----------
--batch-size <Integer: size>             Number of messages to send in a single
                                           batch if they are not being sent
                                           synchronously. please note that this
                                           option will be replaced if max-
                                           partition-memory-bytes is also set
                                           (default: 16384)
--bootstrap-server <String: server to    REQUIRED unless --broker-list
  connect to>                              (deprecated) is specified. The server
                                           (s) to connect to. The broker list
                                           string in the form HOST1:PORT1,HOST2:
                                           PORT2.
--broker-list <String: broker-list>      DEPRECATED, use --bootstrap-server
                                           instead; ignored if --bootstrap-
                                           server is specified.  The broker
                                           list string in the form HOST1:PORT1,
                                           HOST2:PORT2.
--compression-codec [String:             The compression codec: either 'none',
  compression-codec]                       'gzip', 'snappy', 'lz4', or 'zstd'.
                                           If specified without value, then it
                                           defaults to 'gzip'
--help                                   Print usage information.
--line-reader <String: reader_class>     The class name of the class to use for
                                           reading lines from standard in. By
                                           default each line is read as a
                                           separate message. (default: kafka.
                                           tools.
                                           ConsoleProducer$LineMessageReader)
--max-block-ms <Long: max block on       The max time that the producer will
  send>                                    block for during a send request.
                                           (default: 60000)
--max-memory-bytes <Long: total memory   The total memory used by the producer
  in bytes>                                to buffer records waiting to be sent
                                           to the server. This is the option to
                                           control `buffer.memory` in producer
                                           configs. (default: 33554432)
--max-partition-memory-bytes <Integer:   The buffer size allocated for a
  memory in bytes per partition>           partition. When records are received
                                           which are smaller than this size the
                                           producer will attempt to
                                           optimistically group them together
                                           until this size is reached. This is
                                           the option to control `batch.size`
                                           in producer configs. (default: 16384)
--message-send-max-retries <Integer>     Brokers can fail receiving the message
                                           for multiple reasons, and being
                                           unavailable transiently is just one
                                           of them. This property specifies the
                                           number of retries before the
                                           producer give up and drop this
                                           message. This is the option to
                                           control `retries` in producer
                                           configs. (default: 3)
--metadata-expiry-ms <Long: metadata     The period of time in milliseconds
  expiration interval>                     after which we force a refresh of
                                           metadata even if we haven't seen any
                                           leadership changes. This is the
                                           option to control `metadata.max.age.
                                           ms` in producer configs. (default:
                                           300000)
--producer-property <String:             A mechanism to pass user-defined
  producer_prop>                           properties in the form key=value to
                                           the producer.
--producer.config <String: config file>  Producer config properties file. Note
                                           that [producer-property] takes
                                           precedence over this config.
--property <String: prop>                A mechanism to pass user-defined
                                           properties in the form key=value to
                                           the message reader. This allows
                                           custom configuration for a user-
                                           defined message reader.
                                         Default properties include:
                                          parse.key=false
                                          parse.headers=false
                                          ignore.error=false
                                          key.separator=\t
                                          headers.delimiter=\t
                                          headers.separator=,
                                          headers.key.separator=:
                                          null.marker=   When set, any fields
                                           (key, value and headers) equal to
                                           this will be replaced by null
                                         Default parsing pattern when:
                                          parse.headers=true and parse.key=true:
                                           "h1:v1,h2:v2...\tkey\tvalue"
                                          parse.key=true:
                                           "key\tvalue"
                                          parse.headers=true:
                                           "h1:v1,h2:v2...\tvalue"
--reader-config <String: config file>    Config properties file for the message
                                           reader. Note that [property] takes
                                           precedence over this config.
--request-required-acks <String:         The required `acks` of the producer
  request required acks>                   requests (default: -1)
--request-timeout-ms <Integer: request   The ack timeout of the producer
  timeout ms>                              requests. Value must be non-negative
                                           and non-zero. (default: 1500)
--retry-backoff-ms <Long>                Before each retry, the producer
                                           refreshes the metadata of relevant
                                           topics. Since leader election takes
                                           a bit of time, this property
                                           specifies the amount of time that
                                           the producer waits before refreshing
                                           the metadata. This is the option to
                                           control `retry.backoff.ms` in
                                           producer configs. (default: 100)
--socket-buffer-size <Integer: size>     The size of the tcp RECV size. This is
                                           the option to control `send.buffer.
                                           bytes` in producer configs.
                                           (default: 102400)
--sync                                   If set message send requests to the
                                           brokers are synchronously, one at a
                                           time as they arrive.
--timeout <Long: timeout_ms>             If set and the producer is running in
                                           asynchronous mode, this gives the
                                           maximum amount of time a message
                                           will queue awaiting sufficient batch
                                           size. The value is given in ms. This
                                           is the option to control `linger.ms`
                                           in producer configs. (default: 1000)
--topic <String: topic>                  REQUIRED: The topic id to produce
                                           messages to.
--version                                Display Kafka version.
.....................................................................................

How to publish events?
  Events are published into topics

./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic todo-topic
>Hello IBM
>Hello Kafka
>
Press Ctrl Key to come out from the REPL prompt.
.....................................................................................				  Consumer
....................................................................................
How to consume or process messages/events ?
=>Find kakfa topic name eg todo-topic
=>Find host name and port eg localhost:9092
=>if you want to read future message(Current message being published)
=>if you want to read histrical message , from the begining


./bin/kafka-console-consumer.sh --help

Option                                   Description
------                                   -----------
--bootstrap-server <String: server to    REQUIRED: The server(s) to connect to.
  connect to>
--consumer-property <String:             A mechanism to pass user-defined
  consumer_prop>                           properties in the form key=value to
                                           the consumer.
--consumer.config <String: config file>  Consumer config properties file. Note
                                           that [consumer-property] takes
                                           precedence over this config.
--enable-systest-events                  Log lifecycle events of the consumer
                                           in addition to logging consumed
                                           messages. (This is specific for
                                           system tests.)
--formatter <String: class>              The name of a class to use for
                                           formatting kafka messages for
                                           display. (default: kafka.tools.
                                           DefaultMessageFormatter)
--formatter-config <String: config       Config properties file to initialize
  file>                                    the message formatter. Note that
                                           [property] takes precedence over
                                           this config.
--from-beginning                         If the consumer does not already have
                                           an established offset to consume
                                           from, start with the earliest
                                           message present in the log rather
                                           than the latest message.
--group <String: consumer group id>      The consumer group id of the consumer.
--help                                   Print usage information.
--include <String: Java regex (String)>  Regular expression specifying list of
                                           topics to include for consumption.
--isolation-level <String>               Set to read_committed in order to
                                           filter out transactional messages
                                           which are not committed. Set to
                                           read_uncommitted to read all
                                           messages. (default: read_uncommitted)
--key-deserializer <String:
  deserializer for key>
--max-messages <Integer: num_messages>   The maximum number of messages to
                                           consume before exiting. If not set,
                                           consumption is continual.
--offset <String: consume offset>        The offset to consume from (a non-
                                           negative number), or 'earliest'
                                           which means from beginning, or
                                           'latest' which means from end
                                           (default: latest)
--partition <Integer: partition>         The partition to consume from.
                                           Consumption starts from the end of
                                           the partition unless '--offset' is
                                           specified.
--property <String: prop>                The properties to initialize the
                                           message formatter. Default
                                           properties include:
                                          print.timestamp=true|false
                                          print.key=true|false
                                          print.offset=true|false
                                          print.partition=true|false
                                          print.headers=true|false
                                          print.value=true|false
                                          key.separator=<key.separator>
                                          line.separator=<line.separator>
                                          headers.separator=<line.separator>
                                          null.literal=<null.literal>
                                          key.deserializer=<key.deserializer>
                                          value.deserializer=<value.
                                           deserializer>
                                          header.deserializer=<header.
                                           deserializer>
                                         Users can also pass in customized
                                           properties for their formatter; more
                                           specifically, users can pass in
                                           properties keyed with 'key.
                                           deserializer.', 'value.
                                           deserializer.' and 'headers.
                                           deserializer.' prefixes to configure
                                           their deserializers.
--skip-message-on-error                  If there is an error when processing a
                                           message, skip it instead of halt.
--timeout-ms <Integer: timeout_ms>       If specified, exit if no message is
                                           available for consumption for the
                                           specified interval.
--topic <String: topic>                  The topic to consume on.
--value-deserializer <String:
  deserializer for values>
--version                                Display Kafka version.
--whitelist <String: Java regex          DEPRECATED, use --include instead;
  (String)>                                ignored if --include specified.
                                           Regular expression specifying list
                                           of topics to include for consumption.




 ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic todo-topic --from-beginning

Hello IBM
Hello Kafka
How are you?
How is kafka topic
.....................................................................................
		   if you want to publish events and consume in live

--from-beginning
   option reads all events first , then it starts reading current event is being published.
  It reads all messages/events then waits for new event

if you dont use --from-beinning option, it reads only last message delivered
...................................................................................
 			Basic Consumer Properties

=>TimeStamp

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic todo-topic --from-beginning  --property print.timestamp=true
CreateTime:1683174520742        Hello IBM
CreateTime:1683174525906        Hello Kafka
CreateTime:1683175248417        How are you?
CreateTime:1683175264446        How is kafka topic
CreateTime:1683175481732        Kafka enables events streams
CreateTime:1683175514841        Learn kafka
.....................................................................................
				Partition
.....................................................................................	

What is partition?
 In order to distribute the "storage and processing of events" in a topic, Kafka uses the concept partition.
 The topic is made of one or more partition and theses partitions can reside on different nodes in the kafka cluster.
 
The partition is the main unit of stroage for kakfa events, although with tiered storage, which will talk about later.

The partition is also the unit of parallelism.

Events can be produced to a topic in parallel by writing to multiple partitions at the same time. like wise , consumers can spread their workload by individual consumer instances read from different partitions.
if we only use one partition we effectly use one consumer instance.

By default there is one partition.

Lab : 

How to create multiple  partitions for a given topic?
How to break the topic into partitions

Create a topic with 2 partitions.

./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic demo-topic --partitions 2
Created topic demo-topic	

After supplying partition option you can see inside kafka-logs folder

/tmp/kafka-logs
   |
    demo-topic-0
	will have its own log files   
    demo-topic-1
        will have its own log files


Describe the topic after partitions creation:

./bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic demo-topic

Topic: demo-topic       TopicId: yVjUBGbDQPqEWqW2FAoM8Q PartitionCount: 2   
ReplicationFactor: 1
 Configs:
  Topic: demo-topic       Partition: 0    Leader: 0       Replicas: 0     Isr: 0
  Topic: demo-topic       Partition: 1    Leader: 0       Replicas: 0     Isr: 0

....................................................................................
			   Adding more partitions
.....................................................................................

1.create topic with 2 partitions

./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic sales-topic --partitions 2

2.Describe topic details
./bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic sales-topic
Topic: sales-topic      TopicId: AtEnN2MVT1ylKjm1wdbvxQ PartitionCount: 2       ReplicationFactor: 1    Configs:
        Topic: sales-topic      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: sales-topic      Partition: 1    Leader: 0       Replicas: 0     Isr: 0
s

3.Add more partitions
./bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic sales-topic  --partitions 2
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
				Segement
.................................................................................

Topics are broken into partitions, Partitions are broken into segment.

What is Segment?
   Segment is nothing single log file.
Each Segment is stored in a single data file on the disk attached to the broker.

How to list segements(Log files) ?
subugee@LAPTOP-R2TGGFDL:/tmp/kafka-logs/demo-topic-0$ ls -l
total 8
-rw-r--r-- 1 subugee subugee 10485760 May  4 11:28 00000000000000000000.index
-rw-r--r-- 1 subugee subugee        0 May  4 10:50 00000000000000000000.log
-rw-r--r-- 1 subugee subugee 10485756 May  4 11:28 00000000000000000000.timeindex
-rw-r--r-- 1 subugee subugee        8 May  4 11:28 leader-epoch-checkpoint
-rw-r--r-- 1 subugee subugee       43 May  4 10:50 partition.metadata

Here segment is group of files
.log
.index
.timeindex

Segment is just log file where real/actual(Record/Message) is stored in the form of byte array

.log file is actually stores "Events/Records/Message".

Topics are broken down into partitions, where as a partition is broken down into segements.
Each Segment is stored in a single data file on the disk attached to the partion(topic)(broker).

Each segment file size may be 1 GB of data or week of data, which ever limit is attained first.

When the kafka broker receives data for a partion for eg partion-0, as the segment limit is reached, it will close the file and starts a new one.
...................................................................................
			   Log file /Segment architecture
...................................................................................

How event/data/message is stored into segment?

The log file is structured with two parts

1.Actual data
2.Offset 

Actual data is event published into segement as "Record" which is simple byte array.
Offset:
   An offset into a file is simply the character location within that file, usually starting with 0; thus "offset 240" is actually the 241st byte in the file.

  h    b  c  d e f g                       =>Actual data
 -----------------------------------------------------------------------------
  0    1  2  3 4 5 6 7 8 9 10 11 12 13.... => offset
 ------------------------------------------------------------------------------

 Segement 0      Segment 1:         segment 2:             Segement3:Active
offset 0-957=>   offset 958-1675 => offset 1676 to 2453 => Offset:2454-?    <= writes

Onesegement can be active at any point in time- the one data is being written to.

The size of the segement is controlled by two broker configuration

log.segment.bytes

The maximum size of a single log file

Type:	int
Default:	1073741824 (1 gibibyte)

log.segment.ms
 The time kafka will wait before commiting the segemnt if not full 
 default : 1 week

Note:
  A kafa broker keeps an open file handler to every active segement in every partition, even inactive segements.This leads to a usually high number of open file handles, and the OS must be tuned accordingly.

....................................................................................
	    How to break single log(segment) into multiple logs(segment)
....................................................................................
Note:
 In the latest Kafka each log file(segment) will have its own index files

How to configure to create multiple log files?
Just you have edit config/server.properties

############################# Log Retention Policy #############################

The following configurations control the disposal of log segments. The policy can
# be set to delete segments after a period of time, or after a given size has accumulated.

Deletion policy:

# A segment will be deleted whenever *either* of these criteria are met. Deletion always happens
# from the end of the log.

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# A size-based retention policy for logs. Segments are pruned from the log unless the remaining
# segments drop below log.retention.bytes. Functions independently of log.retention.hours.

#log.retention.bytes=1073741824 (1GB)

Create new log file policy:
# The maximum size of a log segment file. When this size is reached a new log segment will be created.
#log.segment.bytes=1073741824(1GB)
log.segment.bytes=1000

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

Lab:

1.Edit server.properties
log.segment.bytes=1000
2.start servers zookeeper and kafka server
3.Start publisher and publish events
4.see the log locations /tmp/kafka-logs

.....................................................................................
			 Index Files
.....................................................................................

Index: 
contains the mappings  of  "offset" to its position in ".log" file
Time Index:
File contains the mappings of timestamp to message offset
Used to search messages based on timestamp.

if you search message based on offset , it uses index file
if you search message based on timestamp,it uses time index file.
....................................................................................
			Multiple Partitions, log segment policy
.....................................................................................
				Topic
				  |
		  ----------------------------------				
		  |          |           |          |
	      partition-0  partition-1 partition-2 partition-n
		  |
	      000000.log
              000011.log
              000012.log
		|
	      0000.log
		 |
	      offset 0 1 2 3 4 ....N
              byte   x y a b c.....
             	   |
	      index and byte position
              
....................................................................................
			       Partitions and Message Distribution
....................................................................................	  
What if i have multiple partions, How messages are routed/distributed to Different Partitions?

Publish Message:
 Producer  default Partitioner and Stick Partitioner:
.....................................................
 A Partitioner is the process that will determine to which partition a specific message will be assigned to.
 In Nutshell Partitioner is simple java class/program, having routing algorthim(which partition to be selected)
  for eg i have three partition, which partition i have to send "this" message

Record===>Publish====>Partitioner===>decide where to go==> P1 or P2 or P3

How partitions are selected by partitioner?
  =>Based on Record only

Record contains information for how to select partition.

Partitioner Algorthims:
.......................
1.Round Robin Algorthim
2.Sticky Partitioner Algorthim
3.Key Based Algorthim.


Round Robin Algorthim:
  This is algorthim used in old kafka less than version no 2.3.
  Where there is no specific partition is specified, and no key is specified(key is   null),Then round robin algorthim is selected.

  Round robin algorthim distributes messages based on round robin fashion

 eg:
  i have 6 partition,
   1st record will go to 1st partition
   2nd record will go to 2nd partition
   so until last partition
   7th message will go to again first partition.

Why round robin is not good?
   if more messages and more partions , there is possiblity of higher latency and low performance.


Sticky Partitioner:
  This is lastest partitioner algorthim.
  It looks like round robin only
  Instead of every distributing messages equally to partions
  which distributes messages as batch.
  Batch by Batch messages are sent.

The DefaultPartitioner now uses a sticky partitioning strategy. This means that records for specific topic with null keys and no assigned partition will be sent to the same partition until the batch is ready to be sent. When a new batch is created, a new partition is chosen. This decreases latency to produce, but it may result in uneven distribution of records across partitions in edge cases. Generally users will not be impacted, but this difference may be noticeable in tests and other situations producing records for a very short amount of time.

Batch size can be controlled by 
 batch.size property

"stick" to a partition until the batch is full or "ligner.ms" has elapsed

After sending the batch, change the partition that is sticky
This will lead to larger batches, and reduced latency.
Over time, the records are still spread evenly across partitions, so the balance of the cluster is not affected.

Overall, there some substatial performance improvements by using the stick-partitioner

Sticky Partitioner = Batching + Round Robin
.....................................................................................
		
Lab:
 How to distribute message without Key :that means we select Sticky Partitioner:
................................................................................

1.Create topic with two partitions

./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic mysticky-topic --partitions 2

2.Produce message to the topic
  ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic mysticky-topic
 
Steps:
1 enter some message  for some time and watch folders 
2. stop the producer and restart ,enter messages

Now you can see how messages are distributed. you can notice two partitions are getting data.

Printing Key and Value:
.......................
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mysticky-topic --from-beginning  --property print.key=true

null    Hello
null    Hai
null    welcome
null    how are you
null    how things are
null    how is kafka
null    how do you think
null    adskfasfkhsaf


Getting partition information via consumer:
...........................................
 ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mysticky-topic --from-beginning  --property print.key=true --property print.partition=true
  
Partition:1     null    Hello
Partition:1     null    Hai
Partition:1     null    welcome
Partition:1     null    how are you
Partition:1     null    how things are
Partition:1     null    how is kafka
Partition:1     null    how do you think
Partition:1     null    adskfasfkhsaf
Partition:1     null    a;dslfkja;fdlksajdf
Partition:1     null    a;ldskfjas;lfkjads;lkfadsjf
Partition:1     null    lasdfkjsa;lfdkjsad;flksajf
Partition:1     null    alsdkfjas;lfdkjsa;flksaf
Partition:1     null    ;ladskjfsa;lkfjsadf;lk
Partition:1     null    adlfafjsad;flasfjsa;fdj
Partition:1     null    asldfj;salfkjsa;flksajf
Partition:1     null    aldsfjas;lfkjdsa
Partition:1     null    adf;safkjsalfsakfjsa;lfkjsadf
Partition:1     null    ;aldjfsa;lkfjdsa;lfkjdsaf
Partition:1     null    adlskfhaskfhsafdashf
Partition:1     null    asdlfjsalf;kjsadf;lksajf;salkfja
Partition:1     null    ;asldkfjas;lfkjdsa;lfkjf
Partition:1     null    aldsfj;afkjas;lfkjdsaf
Partition:1     null    lasdkfsa;lfkjsa;lkfsajf;lsakfja
Partition:1     null    ;adlfkas;flksajf;lsakfjasflkj
Partition:1     null    a;sdlfkjas;lfkjdsaf
Partition:1     null    ;ladkfjsa;lfkja;flkajf
Partition:1     null    kjdakjdfhajfhdsaf
Partition:1     null    ladkfalfkjadflhadkj
Partition:1     null    lakdfhalkfjhlfkjhf
Partition:1     null    ladkfhalkfjhdsaflajdf
Partition:1     null    ladkfahdlkfjdsahf
Partition:1     null    ladkfjhdasflkjahfldsakjfh
Partition:1     null    ladkfjahsdflkajdfhldsakf
Partition:1     null    laksdhflsadkfjhsalkfjh
Partition:1     null    laksdjfhsalkdjfhsaldkfj
Partition:1     null    lakdfadhfksafjh
Partition:0     null    thi
Partition:0     null    a;sldkfjadf
Partition:0     null    aldskfjsalkfd
Partition:0     null    asdfa;lsdkfjasdlkf
Partition:0     null    aldsfjadlfkajdf
Partition:0     null    lkasdjflkdsafj
Partition:0     null    lasdkfjaldskf
Partition:0     null    laskdjflsakfjsadf;lkj
Partition:0     null    a;sldkfjsadlkfjsadf
Partition:0     null    aldsfkjsa;lfkjsadf;k
Partition:0     null    asldfkjsa;flkj
Partition:1     null    asdfasdf
Partition:1     null    adsfdsaf
Partition:1     null    adsfasf

Lab :
You can see live partitions distribution by sending messages  by producer and consumer 

Start two terminals 

1.publisher
2.consumer
.....................................................................................
			Key based Message Distribution
....................................................................................

1.Create topic with two partitions

./bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic mykeys-topic --partitions 2

2.Produce message to the topic
  --property

  ./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic mykeys-topic --property "parse.key=true" --property "key.separator=:"
>project:kafka
>project:java
>project:microservice
>client:ibm
>client:google
>payment:gpay
>payment:neft
>transport:bus
>skill:java

Consumer
 ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mykeys-topic --from-beginning  --property print.key=true --property print.value=true  --property print.partition=true

Partition:1     project kafka
Partition:1     project java
Partition:1     project microservice
Partition:1     client  ibm
Partition:1     client  google
Partition:1     payment gpay
Partition:1     payment neft
Partition:1     transport       bus
Partition:1     skill   java

How to print offset information?
 ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mykeys-topic --from-beginning  --property print.key=true --property print.value=true  --property print.partition=true --property print.offset=true

Partition:1     Offset:0        project kafka
Partition:1     Offset:1        project java
Partition:1     Offset:2        project microservice
Partition:1     Offset:3        client  ibm
Partition:1     Offset:4        client  google
Partition:1     Offset:5        payment gpay
Partition:1     Offset:6        payment neft
Partition:1     Offset:7        transport       bus
Partition:1     Offset:8        skill   java


Sticky-Partitions and offsets
................................
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mysticky-topic --from-beginning  --property print.key=true --property print.value=true  --property print.partition=true --property print.offset=true
Partition:1     Offset:0        null    Hello
Partition:1     Offset:1        null    Hai
Partition:1     Offset:2        null    welcome
Partition:1     Offset:3        null    how are you
Partition:1     Offset:4        null    how things are
Partition:1     Offset:5        null    how is kafka
Partition:1     Offset:6        null    how do you think
Partition:1     Offset:7        null    adskfasfkhsaf
Partition:1     Offset:8        null    a;dslfkja;fdlksajdf
Partition:1     Offset:9        null    a;ldskfjas;lfkjads;lkfadsjf
Partition:1     Offset:10       null    lasdfkjsa;lfdkjsad;flksajf
Partition:1     Offset:11       null    alsdkfjas;lfdkjsa;flksaf
Partition:1     Offset:12       null    ;ladskjfsa;lkfjsadf;lk
Partition:1     Offset:13       null    adlfafjsad;flasfjsa;fdj
Partition:1     Offset:14       null    asldfj;salfkjsa;flksajf
Partition:1     Offset:15       null    aldsfjas;lfkjdsa
Partition:1     Offset:16       null    adf;safkjsalfsakfjsa;lfkjsadf
Partition:1     Offset:17       null    ;aldjfsa;lkfjdsa;lfkjdsaf
Partition:1     Offset:18       null    adlskfhaskfhsafdashf
Partition:1     Offset:19       null    asdlfjsalf;kjsadf;lksajf;salkfja
Partition:1     Offset:20       null    ;asldkfjas;lfkjdsa;lfkjf
Partition:1     Offset:21       null    aldsfj;afkjas;lfkjdsaf
Partition:1     Offset:22       null    lasdkfsa;lfkjsa;lkfsajf;lsakfja
Partition:1     Offset:23       null    ;adlfkas;flksajf;lsakfjasflkj
Partition:1     Offset:24       null    a;sdlfkjas;lfkjdsaf
Partition:1     Offset:25       null    ;ladkfjsa;lfkja;flkajf
Partition:1     Offset:26       null    kjdakjdfhajfhdsaf
Partition:1     Offset:27       null    ladkfalfkjadflhadkj
Partition:1     Offset:28       null    lakdfhalkfjhlfkjhf
Partition:1     Offset:29       null    ladkfhalkfjhdsaflajdf
Partition:1     Offset:30       null    ladkfahdlkfjdsahf
Partition:1     Offset:31       null    ladkfjhdasflkjahfldsakjfh
Partition:1     Offset:32       null    ladkfjahsdflkajdfhldsakf
Partition:1     Offset:33       null    laksdhflsadkfjhsalkfjh
Partition:1     Offset:34       null    laksdjfhsalkdjfhsaldkfj
Partition:1     Offset:35       null    lakdfadhfksafjh
Partition:1     Offset:36       null    asdfasdf
Partition:1     Offset:37       null    adsfdsaf
Partition:1     Offset:38       null    adsfasf
Partition:0     Offset:0        null    thi
Partition:0     Offset:1        null    a;sldkfjadf
Partition:0     Offset:2        null    aldskfjsalkfd
Partition:0     Offset:3        null    asdfa;lsdkfjasdlkf
Partition:0     Offset:4        null    aldsfjadlfkajdf
Partition:0     Offset:5        null    lkasdjflkdsafj
Partition:0     Offset:6        null    lasdkfjaldskf
Partition:0     Offset:7        null    laskdjflsakfjsadf;lkj
Partition:0     Offset:8        null    a;sldkfjsadlkfjsadf
Partition:0     Offset:9        null    aldsfkjsa;lfkjsadf;k
Partition:0     Offset:10       null    asldfkjsa;flkj
.....................................................................................
	How key-value pair messages are distributed to partitions?
.....................................................................................
There is algorthim, called Key hashing algorthim.
Key hashing is the process of determing the mapping of a key to a partition in the default partitioner, the keys are hashed using the mumur2

Targetpartition= Math.abs(Util.murmur2(keyBytes)) % (numPartitions-1)
.....................................................................................
			   Consumer Groups
....................................................................................
A Consumer group is set of consumers which cooperate to consume data from some topics.

The partiontions of all the topics are divided among the consumers in the group
As new group members arrive and old members leave,the partitions re assigened so that each member receices a proportional share of partitions,This is called as "rebalancing group".

The group management is managed by "zookeeper or kraft".

How to implement consumer group?

Lab:

1.create a topic with atleast 2 partiions and send data to it.

2.create a first kafka-console-consumer and assign a group name with "--group"

3.open a new terminal

4.create a second kafka-console-consumer and use the same --group argument.

5.send data to topic and you will see consumers sharing the reads.

Start Zookeeper:

 ./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties

Start Kafka Server:

 ./bin/kafka-server-start.sh -daemon  config/server.properties


create topic:
 ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic my-group-topic --create  --partitions 3 --replication-factor 1
 
 
Start two terminals
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-group-topic --group my-group
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-group-topic --group my-group

Procducer
./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic my-group-topic

Messages are distributed based on round robin fashion...

Consumer groups are helping to distribute large messages into multiple consumers
.....................................................................................
			 Kafka Internal Architecture
....................................................................................

Kafka broker and cluster contains two major components.

1.Control Plane
2.Data Plane

Kafaka cluster is broken into two segement

1.Meta data management
   It is nothing but to take care of Managing the entire cluster   
2.Actual data storage
   Where actual data is stored.

.................................................................................
				Kafka Request

Client requests in kafka fall into two category

=>Produce Request and fetch requests.
    A produce requestis requesting that a batch of data to be written into  a specified topic (producers)

=>Fetch Request:
   A request is requesting data from kafa topics(consumers)


Internal work flow for both producer request (produce request) and consumer (consume request) remanins same.

....................................................................................
				Produce Request
...................................................................................

When a producer is ready to send an event record.

What is event Record?
  Event Record is nothing the message what we sent from the producer, the message structure /event structure is called "Record".

Record consits of the following properties:

1.timestamp
2.key
3.value
4.Headers


When a producer is ready to send an event record,it will use a configurable partitioner to determine the topic partition to assign to the record.

if record has key, then the default partitioner will use a hash of the key to determine the correct partition.
if any records with same key will always be assigned to the same partition.
if the record has no key then a partitioner startegy is used to balance the data in the partitions.


Record Batch:
 Records are accumulated into  record batch. 
 Sending records one at a time would be inefficeint due to the over head of the  network requests   
 So the Producer will accumulate the records assigned to a given partition into  batches.
 Batches provides for much more effective compression when compression is used

The producer has control as to when the record batch should be drained and sent to the broker 
  =This is controlled by two properties
   =>One is by time
   =>The another is size

So once enough time or enough data has been accumulated in those record batches, those record batches will be drained, and will form a produce request.
Then record batches will be sent to the broker. 
.....................................................................................
			-Inside Broker-Network Thread Adds Request to Queue
.....................................................................................

Socket Receive Buffer:
.....................
 The Produce Request first lands in the broker's Socket Receive Buffer.

Network Thread:
...............
  From the socket Receiver buffer, the network thread will pick up the RecordBatch.
  The Network thread is created from the Thread Pool.
  The Network thread will read the data from the socket receive buffer.
  That network thread will handle that particular client request through the rest of   its life cycle.
  The thread forms "Produce Request Object" and add it to the "Request Queue"


Client====>Record====>[RecordBatch]====>Broker's Socket Recieve Buffer==>Thread reads Record Batch===>Forms a [Produce Request Object]===>Produce Request Object added into Request Queue.
.....................................................................................
				IO Threads
.....................................................................................

IO threads are nothing but non blocking threads.

IO operations are performed by

1.Blocking IO
   Dedicated threads are created and works for each io operation
2.NonBlocking IO
  Shared threads are created and shared among multiple io operations

Network threads are blocking io threads , its job is just read batches from the socket receive buffer and writes into request Queue as Request Produce Object.

IO threads are non blocking threads.

Role of IO Threads:
..................
=>A thread from the I/O thread pool will pick up the request from the Queue.
=>The I/O thread will perform some validations
    =>CRC check of the data in the request
    =>Once the validation is over,it will append the data to the physical data       structure of the partition which is commit log.


Kafka Phsyical Storage:
.......................
=>On the disk, the commit log is organized  as collection of segments.
=>Each segment is made up of serval files.
=>One of these is a ".log" file, contains event data.
=>The second a ".index" file, contains a index structure, which maps form a record offset to the position of that record in the .log file.
.....................................................................................
			 Purgatory
....................................................................................

Purgator is the place where data to be replicated to other brokers.
Kafka relies on replication to multiple broker nodes.

Replication:  
   Copying the event records across multiple brokers in the cluster
   Replication makes your events highly available and saves from the fail over

By default , the broker will not give response(ack) on the produce request until it has been replicated to other brokers.

Purgatory Map:
 To avoid tying up the IO threads while waiting for the replication step to complete
The request object will be stored in a map-like data structure called "Purgatory Map"

 Map is just like another buffer , for replication
 From the Map replication starts.
.....................................................................................
			 Response Generation
.....................................................................................

Once the request has been fully replicated, the broker will take the request object out of purgatory, generate a reponse object and place in the response buffer/queue

From the response queue, the network thread will pick up the generated response, and send its data to the socket send buffer.

The network thread also enforces ordering of requests from an indidual client by waiting for all of the bytes for response from the client to be sent before taking another object from the response queue.
.....................................................................................
				 Page Cache
.....................................................................................
Page is like files/data written to disk, ,its index/meta cached by Main Memory.
Before writing data into disk , the kafka writes data into page cache. in order improve disk io the linux operating system provides this feature , kafka uses this feature to write very fast.
.....................................................................................
				Fetch Request-Consumer Side
....................................................................................

In order to consume records, a consumer client sends a fetch request to the broker
by specifing the topic,partition,and offset it wants to consume.
The fetch request goes to the broker's socket receive buffer where it is picked by a network thread.
The network thread puts the request in the request queue, as was done with the produce request.

The I/O thread will take the offset that is included in the fetch request and compare it with the .index file that is part of the partition segment. 

That will tell it exactly the range of bytes that need to be read from the corresponding .log file to add to the response object.


However, it would be inefficient to send a response with every record fetched, or even worse, when there are no records available.

To be more efficient, consumers can be configured to wait for a minimum number of bytes of data, or to wait for a maximum amount of time before returning a response to a fetch request. 

While waiting for these criteria to be met, the fetch request is sent to purgatory

Once the size or time requirements have been met, the broker will take the fetch request out of purgatory and generate a response to be sent back to the client. The rest of the process is the same as the produce request.

Data is reterived from the page cache in order to avoid most disk access.

.....................................................................................				 Data Plane:Replication Protocal
.....................................................................................

In this module we will look at how the data plane handles data replication.
Because distributed commit log system.

Data replication is a critical feature of kafka that allows it to provide high durability and availablity.

How to enable replication?

When create new topic,we can enable replication at the topic level.

When we create new topic, we can specify, explicitly or through defaults, how many replicas you want.

eg:
 ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic my-group-topic --create  --partitions 3 --replication-factor 2

Replication factor :
 Each partition of that topic will be replicated that (1) many times.

my-group-topic partion data to be avilable in 1 machine.

 ./bin/kafka-topics.sh --bootstrap-server localhost:9092 --topic my-group-topic --create  --partitions 3 --replication-factor 3

With a replication factor of N, we can tolerate N-1 failure,without data loss, and while mainitaing availability.
..................................................................................
		   Leader,Follower, and In-Sync Replica(ISR) List
..................................................................................

Leader:
 The leader is a broker whose responsbility getting records from producer and send response to the client and also receive fetch request from the consumers

Followers:
  The brokes who has the copy of records of the master.

ISR List:
  The group of machines/brokers as part of the cluster called "In Sync replica"
..................................................................................
				Leader Epoch
..................................................................................

Each leader is associated with a unique, monotonically increasing number called the leader epoch. 
The epoch is used to keep track of what work was done while this replica was the leader and it will be increased whenever a new leader is elected. The leader epoch is very important for things like log reconciliation, which we’ll discuss shortly.
...................................................................................
			 Communication between leader and follower replicas
....................................................................................
		
The follower replica only starts communicating with leader "asking records" in order to replicate.
This involves two cycles
=>Request
   Follower gives request
=>Response
   Leader gives response

Request Structure:
..................
Inital request 
 
 {
   offset:0	
 }

Leader Reponse:
The leader will respond to the fetch request with the records starting at the specified offset.
 The fetch response will also include the offset for each record and the current leader epoch. 
The followers will then append those records to their own local logs.

Response Structure:

records:[
 (offset:0,epoch:1),
 (offset:1,epoch:1),
 (offset:2,epoch:1)
]
....................................................................................
				Commiting offset partitions


Once all of the followers in the ISR have fetched up to a particular offset, the records up to that offset are considered committed and are available for consumers. This is designated by the high watermark.

The leader is made aware of the highest offset fetched by the followers through the offset value sent in the fetch requests

For example, if a follower sends a fetch request to the leader that specifies offset 3, the leader knows that this follower has committed all records up to offset 3. Once all of the followers have reached offset 3, the leader will advance the high watermark accordingly.
....................................................................................
			Advancing the follower High Watermark
.....................................................................................
The leader, in turn, uses the fetch response to inform followers of the current high watermark. 

Because this process is asynchronous, the followers’ high watermark will typically lag behind the actual high watermark held by the leader.

Response structure with Leader WaterMark Position:

FetchReponse
{
   HighWaterMarkOffset:3,
   records:[
    (offset:3, epoch:1),
    (offset:4, epoch:1)
   ]
}
...................................................................................
			Handling leader failure
...................................................................................
If a leader fails, or if for some other reason we need to choose a new leader, one of the brokers in the ISR will be chosen as the new leader. The process of leader election and notification of affected followers is handled by the control plane. The important thing for the data plane is that no data is lost in the process. That is why a new leader can only be selected from the ISR, unless the topic has been specifically configured to allow replicas that are not in sync to be selected. We know that all of the replicas in the ISR are up to date with the latest committed offset.
Once a new leader is elected, the leader epoch will be incremented and the new leader will begin accepting produce requests.


Temporary Decreased High Watermark:
When a new leader is elected, its high watermark could be less than the actual high watermark. If this happens, any fetch requests for an offset that is between the current leader’s high watermark and the actual will trigger a retriable OFFSET_NOT_AVAILABLE error. The consumer will continue trying to fetch until the high watermark is updated, at which point processing will continue as normal	
....................................................................................
			Partition Replica Reconilation
.....................................................................................

Immediately after a new leader election, it is possible that some replicas may have uncommitted records that are out of sync with the new leader. 

This is why the leader's high watermark is not current yet. It can’t be until it knows the offset that each follower has caught up to.

 We can’t move forward until this is resolved. This is done through a process called replica reconciliation. 

The first step in reconciliation begins when the out-of-sync follower sends a fetch request. 
In our example, the request shows that the follower is fetching an offset that is higher than the high watermark for its current epoch.
.....................................................................................				 Follower Truncates log to Match Leader log
.....................................................................................

The follower will use the information in the fetch response to truncate the extraneous data so that it will be in sync with the leader.
...................................................................................
			Subsequent Fetch with Updated Offset and Epoch
Now the follower can send that fetch request again, but this time with the correct offset.
.....................................................................................		Subsequent Fetch with Updated Offset and Epoch

Now the follower can send that fetch request again, but this time with the correct offset.
.....................................................................................
			Follower broker 102 reconciled
.................................................................................

Structure of Response after reconcilation:
.......................................

FetchReponse
 {
   HighwatermarkOffset:3,
   records:[
     (offset:3,epoch 2),
     (offset:4 ,epoch 2)
   ]
 }

.....................................................................................
			Follower 102 Acknowledges New Records
....................................................................................

When the follower fetches again, the offset that it passes will inform the leader that it has caught up and the leader will be able to increase the high watermark. At this point the leader and follower are fully reconciled, but we are still in an under replicated state because not all of the replicas are in the ISR. Depending on configuration, we can operate in this state, but it’s certainly not ideal.
.....................................................................................
			Follower 101 Rejoins the Cluster
.....................................................................................

At some point, hopefully soon, the failed replica broker will come back online. It will then go through the same reconciliation process that we just described. Once it is done reconciling and is caught up with the new leader, it will be added back to the ISR and we will be back in our happy place.
.....................................................................................
			Handling Failed or Slow Followers

Obviously when a leader fails, it’s a bigger deal, but we also need to handle follower failures as well as followers that are running slow. The leader monitors the progress of its followers. If a configurable amount of time elapses since a follower was last fully caught up, the leader will remove that follower from the in-sync replica set. This allows the leader to advance the high watermark so that consumers can continue consuming current data. If the follower comes back online or otherwise gets its act together and catches up to the leader, then it will be added back to the ISR.
.....................................................................................
				 Data Plane
....................................................................................

1.Produce Request handling
2.Fetch Request Handling
3.Replication Process
....................................................................................
				 Control Plane
.....................................................................................

1.zookeeper
2.kraft
.....................................................................................
			  Cluster Setup Kraft
....................................................................................

Multi node cluster setup with kraft:
....................................

Steps:
1.You need lastest kafka distribution
2.once you extract kafka distribution, you can see 

kafka-3.4.0-src/config/kraft
  server.properties
  broker.propertis
  controller.properties

You know already that kafka broker can be started as 
  broker alone
  controller alone
  broker and controller 

There is configuration called
process.roles=broker
   =>The role of broker 

if you start broker alone, there is property file called "broker.properties"
process.roles=broker

if you start controler alone, there is property file called "controller.properties"
process.roles=controller

if you start broker and controller, there is property file called "server.properties"
process.roles=broker,controller
.....................................................................................
				Node ID

node.id=1 | node.id=2 | node.id=3
 Each node is identified in the cluster by node id.
 It also help us to identify which kraft controller node this is.
.................................................................................
			  Controller configuration
.................................................................................

You can configure the list of controllers in the cluster.
The connect string for the controller quorum

controller.quorum.voters=1@localhost:9093

Here
  "1" is node id=>The node one is controller
  "localhost" is host name of the controller
  "9093"  is port of  the controller.

Lets assume i have two nodes

1.node-1 and node-2

node-1 is designated as broker
node-2 is designated as controller

node-1
 broker.properties
 process.roles=broker
 node.id=1
 controller.quorum.voters=2@localhost:9092

node-2
 controller.properties
 process.roles=controller
 node.id=2
 controller.quorum.voters=3@localhost:9093


1.node-1 and node-2

node-1 is designated as broker and controller
node-2 is designated as controller and broker

node-1
 broker.properties
 process.roles=controller,broker
 node.id=1
 controller.quorum.voters=1@localhost:9092,2@localhost:9092

node-2
 broker.properties
 process.roles=controller,broker
 node.id=2
 controller.quorum.voters=1@localhost:9092,2@localhost:9093
.....................................................................................
			    Socket server settings
....................................................................................

if broker is , broker
.....................
listeners=PLAINTEXT://localhost:9092
 The broker is running on which host and port
PLAINTEXT is name of the protocal used by Kafka


# Name of listener used for communication between brokers.
inter.broker.listener.name=PLAINTEXT


# A comma-separated list of the names of the listeners used by the controller.
# This is required if running in KRaft mode. On a node with `process.roles=broker`, only the first listed listener will be used by the broker.
controller.listener.names=CONTROLLER

If broker is controller:

listeners=CONTROLLER://:9093

if broker is both controller and listener

listeners=PLAINTEXT://:9092,CONTROLLER://:9093,
...................................................................................
			   Log dir

log.dirs=/tmp/kraft-combined-logs

Note if you run multiple brokers and controllers in the machine(single) machine,
you need to specificy the separate location....

log.dirs=/tmp/server-1/kraft-combined-logs
log.dirs=/tmp/server-2/kraft-combined-logs
log.dirs=/tmp/server-3/kraft-combined-logs
.....................................................................................

Steps:
1.You need lastest kafka distribution
2.once you extract kafka distribution, you can see 
3.kafka-3.4.0-src/config/kraft
  server.properties
  broker.propertis
  controller.properties
3.We are going to spin three brokers -all nodes are controllers and brokers


Server -1 Setup:Node-1 Setup:
...............................
server1.properties
Note: here we need to define controller port and broker port should be different
controller port is used for controller communication
broker port is used for external communication like producers and consumers



# The role of this server. Setting this puts us in KRaft mode
process.roles=broker,controller

# The node id associated with this instance's roles
node.id=1

# The connect string for the controller quorum
controller.quorum.voters=1@localhost:19092,2@localhost:19093,3@localhost:19094

listeners=PLAINTEXT://:9092,CONTROLLER://:19092
inter.broker.listener.name=PLAINTEXT
advertised.listeners=PLAINTEXT://localhost:9092
controller.listener.names=CONTROLLER
log.dirs=/tmp/server1/kraft-combined-logs

server2.properties

# The role of this server. Setting this puts us in KRaft mode
process.roles=broker,controller

# The node id associated with this instance's roles
node.id=2

# The connect string for the controller quorum
controller.quorum.voters=1@localhost:19092,2@localhost:19093,3@localhost:19094
listeners=PLAINTEXT://:9093,CONTROLLER://:19093
inter.broker.listener.name=PLAINTEXT
advertised.listeners=PLAINTEXT://localhost:9093
controller.listener.names=CONTROLLER
log.dirs=/tmp/server2/kraft-combined-logs


server3.properties

# The role of this server. Setting this puts us in KRaft mode
process.roles=broker,controller

# The node id associated with this instance's roles
node.id=3

# The connect string for the controller quorum
controller.quorum.voters=1@localhost:19092,2@localhost:19093,3@localhost:19094

listeners=PLAINTEXT://:9094,CONTROLLER://:19094
inter.broker.listener.name=PLAINTEXT
advertised.listeners=PLAINTEXT://localhost:9094
controller.listener.names=CONTROLLER
log.dirs=/tmp/server3/kraft-combined-logs
.....................................................................................

Step 4: Generate clusterid
 in order to establish cluster, we need cluster unique id, through which we establish cluster.

./bin/kafka-storage.sh random-uuid
_54mQ8VFSG6ie-K80KMRLw

We have generated unique cluster id

Step 5: We have to format all the storage directories, this is basically where put in log.dirs properties

./bin/kafka-storage.sh format -t _54mQ8VFSG6ie-K80KMRLw -c ./config/kraft/server1.properties
Formatting /tmp/server1/kraft-combined-logs with metadata.version 3.4-IV0.

./bin/kafka-storage.sh format -t _54mQ8VFSG6ie-K80KMRLw -c ./config/kraft/server2.properties

Formatting /tmp/server2/kraft-combined-logs with metadata.version 3.4-IV0.

./bin/kafka-storage.sh format -t _54mQ8VFSG6ie-K80KMRLw -c ./config/kraft/server3.properties

Formatting /tmp/server3/kraft-combined-logs with metadata.version 3.4-IV0.

Step 6: we need allocate max memory, in order to work cluster properly

export KAFKA_HEAP_OPTS="-Xmx200M -Xms100M"


Step 7: We need to start all kafka servers in daemon mode

./bin/kafka-server-start.sh -daemon ./config/kraft/server1.properties
./bin/kafka-server-start.sh -daemon ./config/kraft/server2.properties
./bin/kafka-server-start.sh -daemon ./config/kraft/server3.properties

Step 8:Test all servers are running
 jcmd | grep kafka
7272 kafka.Kafka ./config/kraft/server2.properties
7113 kafka.Kafka ./config/kraft/server1.properties
7470 kafka.Kafka ./config/kraft/server3.properties

Step 9: create topic 
./bin/kafka-topics.sh --create --topic kraft-test --partitions 3 --replication-factor 3 --bootstrap-server localhost:9092

Created topic kraft-test.

Step 10:
./bin/kafka-topics.sh  --bootstrap-server localhost:9092 --list

Step 11:
./bin/kafka-topics.sh  --bootstrap-server localhost:9092 --l
describe kraft-test

opic: kraft-test       TopicId: YRSN_8SSRzm4GEf2DdvqnQ PartitionCount: 3       ReplicationFactor: 3    Configs: segment.bytes=1073741824
        Topic: kraft-test       Partition: 0    Leader: 1       Replicas: 1,2,3 Isr: 1,2,3
        Topic: kraft-test       Partition: 1    Leader: 2       Replicas: 2,3,1 Isr: 2,3,1
        Topic: kraft-test       Partition: 2    Leader: 3       Replicas: 3,1,2 Isr: 3,1,2

Step 12: produce and consume

./bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic kraft-test

 ./bin/kafka-console-producer.sh --bootstrap-server localhost:9093 --topic kraft-test


Now you are entering message in 9093 node, but messages are delivered via 9093 which means the data is distributed across the cluster
---------------------------------********************............................